#general Titan configuration
gremlin.graph=org.janusgraph.core.JanusGraphFactory
#adjust block size based on number of columns in average transaction
ids.block-size=100000
storage.setup-wait=60000
#adjust the buffer size based on the number of columns (multiple item data model) or the number of vertices (single item data model)
storage.buffer-size=1024
# Metrics configuration - http://docs.janusgraph.org/0.1.0/config-ref.html#_metrics
#metrics.enabled=true
#metrics.prefix=j
# Required; specify logging interval in milliseconds
#metrics.csv.interval=1000
#metrics.csv.directory=metrics
# Turn off JanusGraph retries as we batch and have our own exponential backoff strategy.
storage.write-time=1 ms
storage.read-time=1 ms
storage.backend=com.amazon.janusgraph.diskstorage.dynamodb.DynamoDBStoreManager

#Amazon DynamoDB Storage Backend for JanusGraph configuration
storage.dynamodb.force-consistent-read=true
storage.dynamodb.prefix=v010
storage.dynamodb.metrics-prefix=d
storage.dynamodb.enable-parallel-scans=true
storage.dynamodb.max-self-throttled-retries=60
storage.dynamodb.control-plane-rate=10

# DynamoDB client configuration: credentials
storage.dynamodb.client.credentials.class-name=com.amazonaws.auth.DefaultAWSCredentialsProviderChain
storage.dynamodb.client.credentials.constructor-args=

# DynamoDB client configuration: specify the region and the plugin will automatically use the correct
# HTTPS DynamoDB endpoint for that region.
storage.dynamodb.client.signing-region=us-west-2

# Tune max HTTP connections based on a worse-case estimate of small write latency of 20s for <1KB items
# Writes are at a total of 25 wps so we need 1 HTTP connections to support the load. Remember, reads and writes
# both use these connections, so since the rps are also at 25 rps, lets use 2 HTTP connections. In practice,
# the latency of reads during full graph scans will be larger than that of small writes (because Scan API can
# pull down up to 1MB of data at a time), so you will need to estimate the GetItem/Query/Scan content of your
# read workload and adjust HTTP connections appropriately.
storage.dynamodb.client.connection-max=2
# turn off sdk retries
storage.dynamodb.client.retry-error-max=0

# DynamoDB client configuration: thread pool should start with at least as many HTTP connections as threads.
storage.dynamodb.client.executor.core-pool-size=2
# Do not need more threads in thread pool than the number of http connections
storage.dynamodb.client.executor.max-pool-size=250
storage.dynamodb.client.executor.keep-alive=60000
storage.dynamodb.client.executor.max-concurrent-operations=1
# should be at least as large as the storage.buffer-size
storage.dynamodb.client.executor.max-queue-length=1024

# 750 r/w CU result in provisioning the maximum equal numbers read and write Capacity Units that can
# be set on one table before it is split into two or more partitions for IOPS. If you will have more than one Rexster server
# accessing the same graph, you should set the read-rate and write-rate properties to values commensurately lower than the
# read and write capacity of the backend tables.

storage.dynamodb.stores.edgestore.initial-capacity-read=12
storage.dynamodb.stores.edgestore.initial-capacity-write=12
storage.dynamodb.stores.edgestore.read-rate=12
storage.dynamodb.stores.edgestore.write-rate=12
storage.dynamodb.stores.edgestore.scan-limit=10000

storage.dynamodb.stores.graphindex.initial-capacity-read=9
storage.dynamodb.stores.graphindex.initial-capacity-write=9
storage.dynamodb.stores.graphindex.read-rate=9
storage.dynamodb.stores.graphindex.write-rate=9
storage.dynamodb.stores.graphindex.scan-limit=10000

storage.dynamodb.stores.systemlog.initial-capacity-read=1
storage.dynamodb.stores.systemlog.initial-capacity-write=1
storage.dynamodb.stores.systemlog.read-rate=1
storage.dynamodb.stores.systemlog.write-rate=1
storage.dynamodb.stores.systemlog.scan-limit=10000

storage.dynamodb.stores.titan_ids.initial-capacity-read=1
storage.dynamodb.stores.titan_ids.initial-capacity-write=1
storage.dynamodb.stores.titan_ids.read-rate=1
storage.dynamodb.stores.titan_ids.write-rate=1
storage.dynamodb.stores.titan_ids.scan-limit=10000

storage.dynamodb.stores.system_properties.initial-capacity-read=1
storage.dynamodb.stores.system_properties.initial-capacity-write=1
storage.dynamodb.stores.system_properties.read-rate=1
storage.dynamodb.stores.system_properties.write-rate=1
storage.dynamodb.stores.system_properties.scan-limit=10000

storage.dynamodb.stores.txlog.initial-capacity-read=1
storage.dynamodb.stores.txlog.initial-capacity-write=1
storage.dynamodb.stores.txlog.read-rate=1
storage.dynamodb.stores.txlog.write-rate=1
storage.dynamodb.stores.txlog.scan-limit=10000

# ES config that is required to run GraphOfTheGods
# TODO is it still true that GraphOfTheGods requires ElasticSearch?
index.search.backend=elasticsearch
index.search.directory=elasticsearch
index.search.elasticsearch.client-only=false
index.search.elasticsearch.local-mode=true
index.search.elasticsearch.interface=NODE
